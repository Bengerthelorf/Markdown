# CH2

## æœºå™¨å­¦ä¹ åŸºç¡€

### æ¦‚è¦

#### æœºå™¨å­¦ä¹ çš„å®šä¹‰

> è®©è®¡ç®—æœºä»æ•°æ®ä¸­è¿›è¡Œè‡ªåŠ¨å­¦ä¹ , å¾—åˆ°æŸç§çŸ¥è¯†(è§„å¾‹).

- **Definition of ML (Mitchell, 1997): WELL-POSED LEARNING PROBLEMS.**
  - A computer program is said to learn from experience **E** with respect to some class of tasks **T** and performance measure **P**, if its performance at tasks in **T**, as measured by **P**, improves
with experience **E**.

> ##### Examples
>
> - A computer program that learns to play checkers
>   - **T**ask: playing checkers games;
>   - **E**xperience: obtained by playing games against itself;
>   - **P**erformance Measure: percent of games won against opponents
> - A handwriting recognition learning problem:
>   - Task **T**: recognizing and classifying handwritten words within images
>   - Performance measure **P**: percent of words correctly classified
>   - Training experience **E**: a database of handwritten words with given classifications
> - A robot driving learning problem: an example from (Mitchell, 1997)
>   - Task **T**: driving on public four-lane highways using vision sensors;
>   - Pet-fort-nance **p**: average distance traveled before an error (as judged by hut-nan overseer)
>   - Training experience **E**: a sequence of images and steering commands recorded while observing a human driver;
> - Spam classification
>   - Task **T**: determine if emails are Spam or non-Spam.
>   - Experience **E**: Incoming emails with human classification
>   - Performance Measure **P**: percentage of correct decisions

#### æœºå™¨å­¦ä¹ çš„åˆ†ç±»

ä¾æ®æ•°æ®ä¿¡æ¯çš„ **ç›‘ç£** (æ ‡æ³¨)ç¨‹åº¦, æœºå™¨å­¦ä¹ å¯ä»¥åˆ†ä¸º:

- ç›‘ç£å­¦ä¹ (Supervised Learning)
    > å¤§é‡æ•°æ®è¦(äººå·¥)æ ‡æ³¨
- åŠç›‘ç£å­¦ä¹ (Semi-supervised Learning)
    > éƒ¨åˆ†æ•°æ®æ ‡æ³¨ + å¤§é‡æ•°æ®æ— æ ‡æ³¨
- å¼±ç›‘ç£å­¦ä¹ (Weakly Supervised Learning)
    > æ•°æ®ä»…ç²—ç²’åº¦æ ‡æ³¨
- æ— ç›‘ç£å­¦ä¹ (Unsupervised Learning)
    > å¤§é‡æ•°æ®æ— æ ‡æ³¨

##### åˆ†ç±»æ¦‚è§ˆ

- ç›‘ç£å­¦ä¹ (Supervised Learning)
    > $$
    > loss(D)= \min_{\theta} \frac{1}{N} \sum _{i = 1} ^{N} loss(f(X_i)Y_i)
    > $$
- åŠç›‘ç£å­¦ä¹ (Semi-supervised Learning)
    > $$
    > loss(D_1, D_2)= \min_{\theta} \frac{1}{N} \sum _{i = 1} ^{N} loss(f(X_i)Y_i) + \frac{1}{M} \sum _{i = 1} ^{M} loss(Z_i, R(Z_i, X))
    > $$
    >
    > å…¶ä¸­, $ f(.) $ å±äºæ¨¡å‹é›† $ F $, $ R(Z_i, X) $ å±äºtask-specificå‡½æ•°, è¡¨ç¤ºæ— è¡¨è®°æ•°æ® $ Z_i $ ä¸æ ‡è®°æ•°æ® $ X $ ä¹‹é—´çš„å…³ç³»
- å¼±ç›‘ç£å­¦ä¹ (Weakly Supervised Learning)
    > $$
    > loss(D)= \min_{\theta} \frac{1}{N} \sum _{i = 1} ^{N} loss(f(X_i)C_i)
    > $$
    >
    > å…¶ä¸­, $ C_i $ è¡¨ç¤º **ç²—ç²’åº¦(coarse-grained)** æ ‡è®°, å¦‚: ä»¥ç»„ç»™å‡ºæ ‡è®°
- æ— ç›‘ç£å­¦ä¹ (Unsupervised Learning)
    > - æ— éœ€ä»»ä½•äººå·¥æ ‡æ³¨ä¿¡æ¯
    > - ä»…ä¸€ç»„æ•°æ®, åœ¨è¯¥å…¶ä¸­å¯»æ‰¾è§„å¾‹, å¦‚å­ç©ºé—´æè¿°
    > - **æ–¹æ³•: èšç±»ã€é™ç»´ (PCA) ã€è‡ªç¼–ç å™¨ (AE/VAE)**

##### ç›‘ç£å­¦ä¹ 

- Practical Learning Algorithms
  - Deep Learning
  - Support Vector Machine (SVM)
  - Boosting
  - Random Forest
- Learning Theory
  - Mathematical Formulation of Supervised Learning
  - Generalization
  - Optimization Method
  - Machine Learning Architectures and Approximation Capability

> **Three Components of Deep Learning**
>
> - Model (Architecture)
>   - CNN for images, RNN for speech, Transformers for everything
> - Optimization on Training Data
>   - Learning by optimizing the empirical loss, high-dimensional nonconvex optimization
>   - Practical methods: Stochastic Gradient Descent (SGD) and its variants (Momentum, Adagrad, Adam...)
> - Generalization to Test Data
>   - Generalization bounds
>   - Use regularization to prevent overfitting (dropout, weight decay, early stopping...)

##### æ— ç›‘ç£å­¦ä¹ 

- General Framework:
  - Unlike supervised learning, we do not have the labels of the data in
unsupervised learning framework.
  - Main task: Detect the hidden structure of the "unlabeled" data
  - Two specific tasks:
    - Clustering, a class of methods for discovering unknown subgroups in data.
    - Dimension reduction

> ***P.S.***
>
> Unsupervised Learning by Extreme Value Theory
>
> <https://arxiv.org/abs/2202.09784>

## Details

### åŸºæœ¬æ¦‚å¿µ

1. æ ·æœ¬(ç¤ºä¾‹, sample, instance): æ¯ä¸€ä¸ªæ•°æ®å¯¹è±¡
2. ç‰¹å¾(å±æ€§, attribute, feature): æè¿°æ ·æœ¬æŸæ–¹é¢è¡¨ç°æˆ–æ€§è´¨çš„æ•°æ®
3. æ•°æ®é›†(data set): ä¸€ç»„æ ·æœ¬æ„æˆçš„é›†åˆ
4. è®­ç»ƒé›†(training set): ç”¨äºè®­ç»ƒçš„æ•°æ®é›†
5. æµ‹è¯•æœº(testing set): ç”¨äºæ£€éªŒæ¨¡å‹å¥½åçš„æ•°æ®
6. å‡½æ•°: è¿‘ä¼¼æ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾$x$ä¸æ ‡ç­¾$y$ä¹‹é—´çš„æ˜ å°„å…³ç³»
7. ç®—æ³•(å­¦ä¹ å™¨, algorithm, learner): å¯»æ‰¾åˆ°"æœ€ä¼˜"å‡½æ•°çš„æ–¹æ³•
8. å­¦ä¹ (è®­ç»ƒ, leaning, training): å¯»æ‰¾å‡½æ•°çš„è¿‡ç¨‹

### æœºå™¨å­¦ä¹ çš„è¿‡ç¨‹

é€šè¿‡ **ç®—æ³•** ä½¿å¾—æœºå™¨èƒ½ä»å¤§é‡ **æ•°æ®** ä¸­ **å­¦ä¹ ** è§„å¾‹, ä»è€Œå¾—åˆ°è¾“å…¥æ•°æ®åˆ°ç›®æ ‡æ ‡ç­¾çš„æ˜ å°„ **å‡½æ•°**, å¹¶å¯¹æ–°çš„æ ·æœ¬åšå†³ç­–.

### æœºå™¨å­¦ä¹ çš„ä¸‰ä¸ªåŸºæœ¬è¦ç´ 

- æ¨¡å‹
  - çº¿æ€§æ¨¡å‹
    > $$
    > f(x, \theta) = w ^{T}x + b
    > $$
  - éçº¿æ€§æ¨¡å‹
    > $$
    > f(x, \theta) = w ^{T} \Phi(x) + b
    > $$
    > - å¦‚æœ "$\Phi(x)$" ä¸ºå¯å­¦ä¹ çš„éçº¿æ€§åŸºå‡½æ•°, "$f(x, \theta)$" å°±ç­‰ä»·äºç¥ç»ç½‘ç»œ
- å­¦ä¹ å‡†åˆ™
  - æœŸæœ›é£é™©
    > $$
    > \mathcal{R}(f) = \mathbb{E} _{(x, y) \sim p(x, y)} [\mathcal{L}(f(x), y)]
    > $$
    > - $\mathcal{L(f(x), y)}$ä¸ºæŸå¤±å‡½æ•°
- ä¼˜åŒ–
  - æ¢¯åº¦ä¸‹é™

#### æ¨¡å‹ä¾‹å­

### æŸå¤±å‡½æ•°

- 0-1æŸå¤±å‡½æ•°(0-1 Loss Function)
  > $$
  > \mathcal{L}(y, f(x, \theta)) = \left\{
  > \begin{aligned}
  > 0, & \quad y = f(x, \theta) \\
  > 1, & \quad y \neq f(x, \theta)
  > \end{aligned}
  > \right.
  > $$
- å¹³æ–¹æŸå¤±å‡½æ•°(Qudratic Loss)
  > $$
  > \mathcal{L}(y, \hat{y}) = (y - f(x, \theta)) ^{2}
  > $$
- äº¤å‰ç†µæŸå¤±å‡½æ•°(Cross Entropy Loss)
  > $$
  > \begin{aligned}
  > & p(y = c|x; \theta) = f _{c}(x; \theta), \\
  > & å¹¶æ»¡è¶³ f _{c}(x; \theta) \in [0, 1], \sum _{c = 1} ^{C} f _{c}(x; \theta) = 1
  > \end{aligned}
  > $$
- Hinge æŸå¤±å‡½æ•°(Hinge Loss)
  > $$
  > \mathcal{L}(y, f(x, \theta)) = \max(0, 1 - yf(x; \theta))
  > $$

#### é£é™©æœ€å°åŒ–å‡†åˆ™

- æœŸæœ›é£é™©æœªçŸ¥, é€šè¿‡ç»éªŒé£é™© (Empirical Risk) æ¥è¿‘ä¼¼, å³è®­ç»ƒé›†çš„å¹³å‡æŸå¤±
  > $$
  > \mathcal{R} _{\mathcal{D}} ^{emp}(f) = \frac{1}{N} \sum _{i = 1} ^{N} \mathcal{L}(y^{(n)} f(x^{(n)}; \theta))
  > $$
- ç»éªŒé£é™©æœ€å°åŒ–
- åœ¨é€‰æ‹©åˆé€‚çš„é£é™©å‡½æ•°å, æˆ‘ä»¬å¯»æ‰¾ä¸€ä¸ªå‚æ•° $\theta _{*}$, ä½¿å¾—ç»éªŒé£é™©å‡½æ•°æœ€å°åŒ–
  > $$
  > \theta ^{*} = \arg \min _{\theta} \mathcal{R} _{\mathcal{D}} ^{emp}(\theta)
  > $$

### æœ€ä¼˜åŒ–é—®é¢˜

> é€‰æ‹©å®Œé£é™©å‡½æ•°å, æœºå™¨å­¦ä¹ é—®é¢˜å°±è½¬åŒ–æˆä¸ºä¸€ä¸ªæœ€ä¼˜åŒ–é—®é¢˜

![convex_vs_non-convex](https://qph.cf2.quoracdn.net/main-qimg-f848fbbcbf279aadeacb7bd9850d5ed1)

$$
\min _{x} f(x)
$$

#### æ¢¯åº¦ä¸‹é™æ³•(Gradient Descent)

$$
\begin{aligned}
  \theta _{t + 1} & = \theta _{t} - \alpha \frac{\partial \mathcal{R}(\theta)}{\partial \theta _{t}} \\
  & = \theta _{t} - \alpha \frac{1}{N} \sum _{i = 1} ^{N} \frac{\partial \mathcal{L}(\theta _{t}; x^{(i)}, y^{(i)})}{\partial \theta}
\end{aligned}
$$

> ğŸ‘† å…¶ä¸­, **æœç´¢æ­¥é•¿ $\alpha$**, ä¹Ÿå« **å­¦ä¹ ç‡(learning rate)**

##### éšæœºæ¢¯åº¦ä¸‹é™æ³•(Stochastic Gradient Descent, SGD)

- å¦‚æœç›®æ ‡å‡½æ•°æ˜¯æ•´ä¸ªè®­ç»ƒé›†çš„é£é™©å‡½æ•°(æ‰¹é‡æ¢¯åº¦ä¸‹é™), è®¡ç®—å¼€é”€å¾ˆå¤§.
- ä¸ºäº†å‡å°‘æ¯æ¬¡è¿­ä»£çš„è®¡ç®—å¤æ‚åº¦, å¯ä»¥åœ¨æ¯æ¬¡è¿­ä»£çš„æ—¶å€™åªé‡‡æ ·ä¸€ä¸ªæ ·æœ¬, è®¡ç®—è¿™ä¸ªæ ·æœ¬æŸå¤±çš„æ¢¯åº¦å¹¶æ›´æ–°å‚æ•°, å³éšæœºæ¢¯åº¦ä¸‹é™. å½“ç»è¿‡è¶³å¤Ÿæ¬¡æ•°è¿­ä»£, éšæœºæ¢¯åº¦ä¸‹é™ä¹Ÿå¯ä»¥æ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜è§£.
  > $$
  > \theta _{t + 1} = \theta _{t} - \alpha \frac{\partial \mathcal{L}(\theta _{t}; x^{(i)}, y^{(i)})}{\partial \theta}
  > $$
- å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™æ³•(mini - batch gradient descent)æ˜¯æ‰¹é‡æ¢¯åº¦ä¸‹é™å’Œéšæœºæ¢¯åº¦ä¸‹é™çš„æŠ˜ä¸­, æ¯æ¬¡é€‰å–ä¸€å°éƒ¨åˆ†è®­ç»ƒæ ·æœ¬æ¥è¿›è¡Œæ¢¯åº¦ä¸‹é™è®¡ç®—. æ—¢å…¼é¡¾éšæœºæ¢¯åº¦ä¸‹é™çš„ä¼˜ç‚¹, ä¹Ÿæé«˜äº†è®­ç»ƒæ•ˆç‡.
- å®é™…åº”ç”¨ä¸­, å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™æ³•, é€æ¸æˆä¸ºå¤§è§„æ¨¡æœºå™¨å­¦ä¹ çš„ä¸»æµä¼˜åŒ–ç®—æ³•.

> æµç¨‹
>
> ![SGD](./img/ch2_SGD.png)
> $$
> \begin{align*}
> & \quad \textbf{è¾“å…¥} \text{}{: è®­ç»ƒé›†} \mathcal{D} = \{ (x^{(n)}, y^{(n)}) \} ^{N} _{n = 1}, éªŒè¯é›† \mathcal{V}, å­¦ä¹ ç‡ \alpha \\
> & 1 \quad éšæœºåˆå§‹åŒ– \theta; \\
> & 2 \quad \text{repeat} \\
> & 3 \quad \quad \text{å¯¹è®­ç»ƒé›†} \mathcal{D} ä¸­çš„æ ·æœ¬éšæœºé‡æ’åº; \\
> & 4 \quad \quad for \quad n = 1 \cdots N \quad \text{do} \\
> & 5 \quad \quad \quad \text{ä»è®­ç»ƒé›†} \mathcal{D} \text{ä¸­é€‰å–æ ·æœ¬} (x^{(n)}, y^{(n)}); \\
> &  \quad \quad \quad \quad // \quad \text{æ›´æ–°å‚æ•°} \\
> & 6 \quad \quad \quad \theta \leftarrow \theta - \alpha \frac{\partial \mathcal{L}(\theta; x^{(n)}, y^{(n)})}{\partial \theta} \\
> & 7 \quad \quad \text{end} \\
> & 8 \quad \text{until} \quad \text{æ¨¡å‹} f(x; \theta) \text{åœ¨éªŒè¯é›†} \mathcal{V} \text{ä¸Šçš„é”™è¯¯ç‡ä¸å†ä¸‹é™} \\
> & \quad \textbf{è¾“å‡º} \theta
> \end{align*}
> $$

#### è¿‡æ‹Ÿåˆ

è¿‡æ‹Ÿåˆï¼šç»éªŒé£é™©æœ€å°åŒ–åŸåˆ™å¾ˆå®¹æ˜“å¯¼è‡´æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šé”™è¯¯ç‡å¾ˆä½ï¼Œä½†æ˜¯åœ¨æœªçŸ¥æ•°æ®ä¸Šé”™è¯¯ç‡å¾ˆé«˜ã€‚è¿‡æ‹Ÿåˆé—®é¢˜å¾€å¾€æ˜¯ç”±äºè®­ç»ƒæ•°æ®å°‘å’Œå™ªå£°ç­‰åŸå› é€ æˆçš„ã€‚

#### æ³›åŒ–é”™è¯¯

- æœŸæœ›é¢„æœŸ
  > $$
  > \mathcal{R}(f) = \mathbb{E} _{(x, y) \sim p(x, y)} [\mathcal{L}(f(x), y)]
  > $$
  >
  > - çœŸå®åˆ†å¸ƒ:
  > ![çœŸå®åˆ†å¸ƒ](./img/ch2_2.png)
- ç»éªŒé£é™©
  > $$
  > \mathcal{R} _{\mathcal{D}} ^{emp}(f) = \frac{1}{N} \sum _{i = 1} ^{N} \mathcal{L}(y^{(n)} f(x^{(n)}; \theta))
  > $$
  >
  > - è®­ç»ƒé›†åˆ†å¸ƒ:
  > ![è®­ç»ƒé›†åˆ†å¸ƒ](./img/ch2_3.png)

å¦‚ä½•å‡å°‘æ³›åŒ–é”™è¯¯ï¼Ÿ
> **æ­£åˆ™åŒ–!!**

#### æ­£åˆ™åŒ–

- å¦¨ç¢è¿‡åº¦ä¼˜åŒ–
  1. å¢åŠ ä¼˜åŒ–çº¦æŸ
     - L1/L2 çº¦æŸã€æ•°æ®å¢å¼º
  2. å¹²æ‰°ä¼˜åŒ–è¿‡ç¨‹
     - æƒé‡è¡°å‡ï¼Œéšæœºæ¢¯åº¦ä¸‹é™ï¼Œæå‰åœæ­¢

#### æå‰åœæ­¢

ä½¿ç”¨ä¸€ä¸ªéªŒè¯é›†(validation Dataset)æ¥æµ‹è¯•æ¯ä¸€æ¬¡è¿­ä»£çš„å‚æ•°åœ¨éªŒè¯é›†ä¸Šæ˜¯å¦æœ€ä¼˜ã€‚å¦‚æœåœ¨éªŒè¯é›†ä¸Šçš„é”™è¯¯ç‡ä¸å†ä¸‹é™ï¼Œå°±åœæ­¢è¿­ä»£ã€‚

### å‚æ•°å­¦ä¹ (ä»¥çº¿æ€§å›å½’ä¸ºä¾‹)

- ç»éªŒé£é™©æœ€å°åŒ–(æœ€å°äºŒä¹˜æ³•)
- ç»“æ„é£é™©æœ€å°åŒ–(å²­å›å½’)
- æœ€å¤§ä¼¼ç„¶ä¼°è®¡
- æœ€å¤§åéªŒä¼°è®¡

#### æœ€å°äºŒä¹˜æ³•(Least Square Method, LSM)

- ä½¿ç”¨å¹³æ–¹æŸå¤±å‡½æ•° MSE ä½œä¸ºç»éªŒé£é™©æœ€å°åŒ–çš„æŸå¤±
  > $$
  > \begin{aligned}
  > \mathcal{R}(w) &= \sum _{n = 1} ^{N} \mathcal{L}(y^{(n)}, f(x^{(n)}; w)) \\
  > &= \frac{1}{2} \sum _{n = 1} ^{N} (y^{(n)} - w ^{T}x^{(n)}) ^{2} \\
  > &= \frac{1}{2} || y - X ^{T}w || ^{2}
  \end{aligned}
  > $$
- å…¶ä¸­ $y$ æ˜¯æ‰€æœ‰æ ·æœ¬æ ‡ç­¾æ„æˆçš„åˆ—å‘é‡ï¼Œ$X$ æ˜¯æ‰€æœ‰è¾“å…¥æ ·æœ¬ç‰¹å¾æ„æˆçš„çŸ©é˜µï¼ŒæŸå¤±å¯¹å‚æ•° $w$ æ±‚åå¯¼å¾—
  > $$
  > \begin{aligned}
  > \frac{\partial \mathcal{R}(w)}{\partial w} &= \frac{1}{2} \frac{\partial || y - X ^{T}w || ^{2}}{\partial w} \\
  > &= - X(y - X ^{T}w)
  > \end{aligned}
  > $$
- ä»¤ $\frac{\partial}{\partial w} \mathcal{R} (w)$, å¾—åˆ°æœ€ä¼˜çš„å‚æ•° $w ^{*}$ ä¸º
  > $$
  > w ^{*} = (X X ^{T}) ^{-1} X y
  > $$

#### ç»“æ„é£é™©æœ€å°åŒ–(å²­å›å½’, Ridge Regression)

ä½¿ç”¨ LSM éœ€è¦ä¿è¯ç‰¹å¾ä¹‹é—´äº’ç›¸ç‹¬ç«‹ï¼Œå³ $XX ^{T}$ å¯é€†ã€‚ä½†å³ä½¿ $XX^{T}$ å¯é€†ï¼Œç‰¹å¾ä¹‹é—´å¦‚æœå­˜åœ¨çº¿æ€§ç›¸å…³æ€§ï¼Œä»ç„¶ä¼šä½¿å¾— LSM çš„è®¡ç®—ä¸ç¨³å®šã€‚è€Œå²­å›å½’åˆ™ç»™ $XX^{T}$ å¯¹è§’çº¿å…ƒç´ åŠ äº†ä¸€ä¸ªå¸¸æ•°, ä½¿ $(XX^{T} + \lambda I)$ æ»¡ç§©ï¼Œå…¶æœ€ä¼˜å‚æ•° $w ^{*}$ ä¸º

$$
w ^{*} = (XX^{T} + \lambda I) ^{-1} X y
$$

å²­å›å½’ä¹Ÿå¯ä»¥çœ‹åšæ˜¯ç»“æ„é£é™©å‡†åˆ™ä¸‹çš„æœ€å°äºŒä¹˜ä¼°è®¡(å¸¦æ­£åˆ™åŒ–é¡¹)ï¼Œç›®æ ‡å‡½æ•°ä¸º

$$
\mathcal{R}(w) = \frac{1}{2} || y - X ^{T}w || ^{2} + \frac{\lambda}{2} || w || ^{2}
$$

#### æœ€å¤§ä¼¼ç„¶ä¼°è®¡(Maximum Likelihood Estimation, MLE)

> ä»æ¡ä»¶æ¦‚ç‡ $p(y|x)$ å»ºæ¨¡

å‡è®¾ $y$ ä¸ºä¸€ä¸ªéšæœºå˜é‡ï¼Œç”±å‡½æ•° $f(x; w) = w^{T}x$ åŠ ä¸Šä¸€ä¸ªéšæœºå™ªå£°ï¼Œå…¶ä¸­å™ªå£° $\epsilon$ æœä»å‡å€¼ 0 ï¼Œæ–¹å·® $\sigma ^{2}$ çš„é«˜æ–¯åˆ†å¸ƒï¼Œè¿™æ ·ç›®æ ‡ $y$ æœä»å‡å€¼ $w^{T}x$ï¼Œæ–¹å·® $\sigma ^{2}$ çš„é«˜æ–¯åˆ†å¸ƒ

$$
\begin{aligned}
  p(y|x; w) &= \mathcal{N}(y; w^{T}x, \sigma ^{2}) \\
  &= \frac{1}{\sqrt{2 \pi \sigma ^{2}}} \exp \left( - \frac{(y - w^{T}x) ^{2}}{2 \sigma ^{2}} \right)
\end{aligned}
$$

å‚æ•° $w$ åœ¨è®­ç»ƒé›†ä¸Šçš„ä¼¼ç„¶å‡½æ•°ä¸º

$$
\begin{aligned}
  p(y|x; w, \sigma) &= \prod _{n = 1} ^{N} p(y^{(n)}|x^{(n)}; w, \sigma) \\
  &= \prod _{n = 1} ^{N} \mathcal{N}(y ^{(n)}; w^{T}x^{(n)}, \sigma ^{2})
\end{aligned}
$$

å…¶å¯¹æ•°ä¼¼ç„¶å‡½æ•°(Log Likelihood Function)ä¸º:

$$
\log p(y|x; w, \sigma) = \sum _{n = 1} ^{N} \log \mathcal{N}(y ^{(n)}; w^{T}x^{(n)}, \sigma ^{2})
$$

æœ€å¤§ä¼¼ç„¶ä¼°è®¡MLEå³æ˜¯æ‰¾åˆ°ä¸€ç»„å‚æ•° $w$ ä½¿å¾—ä¼¼ç„¶å‡½æ•°$p(y|X; w, \sigma)$æœ€å¤§, ç­‰ä»·äºå¯¹æ•°ä¼¼ç„¶å‡½æ•°$\log p(y|X; w, \sigma)$æœ€å¤§.

$$
\text{ä»¤} \frac{\partial \log p(y|X; w, \sigma)}{\partial w} = 0 \\
\Downarrow \\
w ^{ML} = (X X ^{T}) ^{-1} X y
$$

MLE å¯ä»¥å¾—åˆ°å’Œæœ€å°äºŒä¹˜æ³•ä¸€æ ·çš„ç»“æœã€‚

#### æœ€å¤§åéªŒä¼°è®¡(Maximum A Posteriori Estimation, MAP)

ä¸ºäº†é¿å…è¿‡æ‹Ÿåˆï¼Œå¯ä»¥ç»™å‚æ•°åŠ ä¸Šä¸€äº›å…ˆéªŒçŸ¥è¯†ã€‚å‡è®¾å‚æ•° $w$ ä¸ºä¸€ä¸ªéšæœºå‘é‡ï¼Œå¹¶æœä»ä¸€ä¸ªå…ˆéªŒåˆ†å¸ƒ $p(w; v)$, ä»¤ $p(w; v)$ ä¸ºå„å‘åŒæ€§é«˜æ–¯åˆ†å¸ƒ $p(w; v) = \mathcal{N}(w; 0, v^{2}I)$, å…¶ä¸­ $v^{2}$ ä¸ºæ–¹å·®ã€‚

æ ¹æ®è´å¶æ–¯å…¬å¼ï¼Œå‚æ•° $w$ çš„åéªŒåˆ†å¸ƒä¸º

$$
\begin{aligned}
  p(w|X, y; v, \sigma) &= \frac{p(w, y|X; v, \sigma)}{\sum _{w} p(w, y|X; v, \sigma)} \\
  & \propto p(y|X, w; \sigma) p(w; v)
\end{aligned}
$$

è¿™ç§ä¼°è®¡å‚æ•° $w$ çš„åéªŒæ¦‚ç‡åˆ†å¸ƒçš„æ–¹æ³•ä¸ºè´å¶æ–¯ä¼°è®¡ï¼Œè´å¶æ–¯ä¼°è®¡æ˜¯ä¸€ç§å‚æ•°çš„åŒºé—´ä¼°è®¡ï¼Œå¦‚æœè¦å¾—åˆ°ä¸€ä¸ªæœ€ä¼˜çš„å‚æ•°å€¼ï¼ˆç‚¹ä¼°è®¡ï¼‰å¯ä»¥ä½¿ç”¨æœ€å¤§åéªŒä¼°è®¡ MAP ï¼Œå³æœ€ä¼˜å‚æ•°ä¸ºåéªŒåˆ†å¸ƒ $p(w|X, y; v, \sigma)$ ä¸­å¯†åº¦æœ€é«˜çš„å‚æ•°

$$
w ^{MAP} = \arg \max _{w} p(w|X, y; v, \sigma)p(w; v)
$$

ä¼¼ç„¶å‡½æ•°æ»¡è¶³ä¹‹å‰æ¨å¯¼çš„é«˜æ–¯å¯†åº¦å‡½æ•°

$$
\begin{aligned}
  p(y|X, w; \sigma) &= \prod _{n = 1} ^{N} p(y^{(n)}|x^{(n)}, w; \sigma) \\
  &= \prod _{n = 1} ^{N} \mathcal{N}(y ^{(n)}; w^{T}x^{(n)}, \sigma ^{2}) \\
\end{aligned}
$$

å…¶å¯¹æ•°ä¼¼ç„¶ä¸º

$$
\begin{aligned}
  \log p(w|X, y; v, \sigma) & \propto \log p(y|X, w; \sigma) + \log p(w; v) \\
  & \propto - \frac{1}{2 \sigma ^{2}} \sum _{n = 1} ^{N} (y ^{(n)} - w^{T}x^{(n)}) ^{2} - \frac{1}{2v^{2}} w ^{T}w \\
  &= - \frac{1}{2 \sigma ^{2}} || y - X ^{T}w || ^{2} - \frac{1}{2v^{2}} w^{T}w
\end{aligned}
$$

å…¶ä¸­æ­£åˆ™åŒ–ç³»æ•°ä¸º $\lambda = \frac{\sigma ^{2}}{v ^{2}}$

#### å‚æ•°å­¦ä¹ æ€»ç»“

|  | æ— å…ˆéªŒ | å¼•å…¥å…ˆéªŒ |
| :---: | :---: | :---: |
| å¹³æ–¹è¯¯å·® | ç»éªŒé£é™©æœ€å°åŒ– | ç»“æ„é£é™©æœ€å°åŒ– |
| æ¦‚ç‡ | æœ€å¤§ä¼¼ç„¶ä¼°è®¡ | æœ€å¤§åéªŒä¼°è®¡ |
|  | $w^{ML} = (XX^{T})^{-1}Xy$ | $w ^{*} = (XX^{T} + \lambda I)^{-1}Xy$ |
