> Prove $E(\hat{\sigma} ^{2}) = \sigma ^{2}$

要证明$E(\hat{\sigma}^2) = \sigma^2$，我们需要假设误差项$\epsilon$服从均值为零，方差为$\sigma^2$的正态分布，即$\epsilon \sim N(0, \sigma^2)$。这意味着因变量$y$也服从均值为$X\beta$，方差为$\sigma^2$的正态分布，即$y \sim N(X\beta, \sigma^2)$。

给定$X$和$\beta$时，$y$的似然函数为：

$$L(y|X,\beta) = \prod_{i=1}^n f(y_i|x_i,\beta)$$

其中$f(y_i|x_i,\beta)$是正态分布的概率密度函数在$y_i$处的取值。代入正态密度的公式，我们得到：

$$L(y|X,\beta) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y_i - x_i'\beta)^2}{2\sigma^2}\right)$$

对两边取自然对数，我们得到对数似然函数：

$$\log L(y|X,\beta) = -\frac{n}{2} \log(2\pi\sigma^2) - \frac{1}{2\sigma^2} \sum_{i=1}^n (y_i - x_i'\beta)^2$$

要找到$\sigma^2$的最大似然估计量，我们需要对$\sigma^2$最大化对数似然函数。求一阶导数并令其为零，我们得到：

$$\frac{\partial \log L(y|X,\beta)}{\partial \sigma^2} = -\frac{n}{2\sigma^2} + \frac{1}{2(\sigma^2)^2} \sum_{i=1}^n (y_i - x_i'\beta)^2 = 0$$

解出$\sigma^2$，我们得到：

$$\hat{\sigma}^2_{MLE} = \frac{1}{n} \sum_{i=1}^n (y_i - x_i'\beta)^2$$

这与OLS估计量$\hat{\sigma}^2$完全相同。因此，我们证明了$E(\hat{\sigma}^2) = \sigma^2$。